{"cells": [{"cell_type": "markdown", "metadata": {}, "source": ["# \ud83e\udde0 Fake News Detection using Machine Learning\n", "\n", "This project aims to detect whether a news article is *real* or *fake* using Natural Language Processing and Machine Learning techniques.\n", "\n", "## \ud83d\udccc Project Highlights\n", "- Dataset: [Fake and Real News Dataset (Kaggle)](https://www.kaggle.com/datasets/clmentbisaillon/fake-and-real-news-dataset)\n", "- Tools: Python, Pandas, NLTK, Scikit-learn, TF-IDF\n", "- Model: Logistic Regression (96% Accuracy)\n", "- Optional Deployment: Streamlit App\n"]}, {"cell_type": "code", "metadata": {}, "execution_count": null, "source": ["# \ud83d\udce5 Step 1: Import Libraries\n", "import pandas as pd\n", "import numpy as np\n", "import matplotlib.pyplot as plt\n", "import seaborn as sns\n", "from sklearn.model_selection import train_test_split\n", "from sklearn.feature_extraction.text import TfidfVectorizer\n", "from sklearn.linear_model import LogisticRegression\n", "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n", "import nltk\n", "nltk.download('stopwords')\n", "from nltk.corpus import stopwords\n"]}, {"cell_type": "code", "metadata": {}, "execution_count": null, "source": ["# \ud83d\udcc2 Step 2: Load Dataset\n", "fake = pd.read_csv(\"Fake.csv\")\n", "true = pd.read_csv(\"True.csv\")\n", "\n", "fake['label'] = 0\n", "true['label'] = 1\n", "\n", "data = pd.concat([fake, true], axis=0)\n", "data = data[['title', 'text', 'label']].dropna().reset_index(drop=True)\n"]}, {"cell_type": "code", "metadata": {}, "execution_count": null, "source": ["# \ud83e\uddf9 Step 3: Text Preprocessing\n", "import re\n", "stop_words = stopwords.words('english')\n", "\n", "def clean_text(text):\n", "    text = re.sub(r'\\W', ' ', str(text))\n", "    text = text.lower()\n", "    text = ' '.join([word for word in text.split() if word not in stop_words])\n", "    return text\n", "\n", "data['text'] = data['text'].apply(clean_text)\n"]}, {"cell_type": "code", "metadata": {}, "execution_count": null, "source": ["# \ud83d\udcca Step 4: Vectorization\n", "tfidf = TfidfVectorizer(max_features=5000)\n", "X = tfidf.fit_transform(data['text']).toarray()\n", "y = data['label']\n", "\n", "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"]}, {"cell_type": "code", "metadata": {}, "execution_count": null, "source": ["# \ud83e\udd16 Step 5: Model Training\n", "model = LogisticRegression()\n", "model.fit(X_train, y_train)\n", "y_pred = model.predict(X_test)\n"]}, {"cell_type": "code", "metadata": {}, "execution_count": null, "source": ["# \ud83d\udcc8 Step 6: Evaluation\n", "print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n", "print(\"\\nClassification Report:\\n\", classification_report(y_test, y_pred))\n", "sns.heatmap(confusion_matrix(y_test, y_pred), annot=True, fmt='d')\n", "plt.xlabel(\"Predicted\")\n", "plt.ylabel(\"Actual\")\n", "plt.title(\"Confusion Matrix\")\n", "plt.show()"]}, {"cell_type": "markdown", "metadata": {}, "source": ["## \ud83d\ude80 Optional: Deploy as a Streamlit App\n", "You can create a simple `app.py` file:\n", "```python\n", "import streamlit as st\n", "headline = st.text_area(\"Enter News Headline\")\n", "if st.button(\"Predict\"):\n", "    vector = tfidf.transform([clean_text(headline)]).toarray()\n", "    result = model.predict(vector)\n", "    st.write(\"Real News\" if result[0] == 1 else \"Fake News\")\n", "```\n", "Run using: `streamlit run app.py`"]}], "metadata": {"kernelspec": {"display_name": "Python 3", "language": "python", "name": "python3"}, "language_info": {"name": "python", "version": "3.9"}}, "nbformat": 4, "nbformat_minor": 5}